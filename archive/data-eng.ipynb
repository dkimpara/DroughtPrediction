{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1db47b1-a586-4db7-a836-8d4d3da8b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628d8e2-66ce-4699-8229-4949ec81c74e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task Description\n",
    "Predict drought level for the next 6 weeks, one prediction per week. Using 180 days of previous data.\n",
    "## This notebook: creating pipelines and saving transformed data as CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168fd2a8-d135-4980-b6a4-35461d3fcc13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "We want to make two sub pipelines:\n",
    "raw df -> semi-processed save to csv -> fully processed\n",
    "due to the capabilities of pipelines, we will need two pipelines:\n",
    "* encoding training Ys according to interpolation\n",
    "* encoding test Ys separately (discrete values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9370d965-11de-46d1-9077-404308f099fa",
   "metadata": {},
   "source": [
    "data is quite big so we want to pre-process and save CSVs whenever possible\n",
    "\n",
    "Pipeline 1 (for the training data)\n",
    "1. encode date\n",
    "\n",
    "Get training labels. we should save these Y labels separately for memory efficiency etc\n",
    "\n",
    "2. round labels (Y/N)\n",
    "3. interpolate NaNs (linear or nearest )\n",
    "4. create 6 week ahead prediction vectors\n",
    "\n",
    "Losses that we can use for training for each training label set:\n",
    "* nearest interpolation, rounded labels: discrete\n",
    "* nearest interpolation, unrounded: continuous\n",
    "* linear interpolation: continuous \n",
    "\n",
    "(when evaluating on test set, we will always round predictions)\n",
    "\n",
    "Pipeline 2 // training data:\n",
    "1. normalize (with var or no)\n",
    "2. add soil data (Y/N) + linearize (param: int, past observations)\n",
    "\n",
    "For the test data:\n",
    "1. delete NaN rows\n",
    "2. round labels\n",
    "3. create 6 week ahead prediction vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608bcd2f-5ffe-436d-9c0c-53a95b58cd18",
   "metadata": {},
   "source": [
    "## Pipeline 1 with pd.pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ac8367-2dbd-440a-b17a-7aa8935a954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_nans(padata, pkind = 'linear'):\n",
    "    \"\"\"\n",
    "    see: https://stackoverflow.com/a/53050216/2167159\n",
    "    \"\"\"\n",
    "    aindexes = np.arange(padata.shape[0])\n",
    "    agood_indexes, = np.where(np.isfinite(padata))\n",
    "    f = interp1d(agood_indexes\n",
    "               , padata[agood_indexes]\n",
    "               , bounds_error=False\n",
    "               , copy=False\n",
    "               , fill_value=\"extrapolate\"\n",
    "               , kind=pkind)\n",
    "    return f(aindexes)\n",
    "\n",
    "def sort_df(df):\n",
    "    df.set_index('date', append=True, inplace=True)\n",
    "    df.sort_index(inplace=True) #sort ascending for both indices\n",
    "    df.reset_index(level='date', inplace=True)\n",
    "    return df\n",
    "\n",
    "#simple centering by subtracting the mean. do this before date encoding\n",
    "def normalize(df):\n",
    "    #past scores can be part of the training data\n",
    "    subdf = df.drop(columns=['date', 'score'])\n",
    "    df.loc[:, ~df.columns.isin(['date', 'score'])] = (subdf-subdf.mean()).round(2)\n",
    "    return df\n",
    "\n",
    "\n",
    "def sin_cos_encoder(df):\n",
    "    # first convert date to datetime col \n",
    "    #replace date col, no need to drop old cols\n",
    "    df['date'] = pd.to_datetime(df['date'], yearfirst=True, \n",
    "                                          format=\"%Y/%m/%d\")\n",
    "    df['sin'] = np.sin(2 * np.pi * df['date'].dt.dayofyear / 366)\n",
    "    df['cos'] = np.cos(2 * np.pi * df['date'].dt.dayofyear / 366)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def interpolate_round(df, pkind='nearest', rnd=True):\n",
    "    '''input df must be sorted and have index fips and score col'''\n",
    "    #round values\n",
    "    if rnd:\n",
    "        df['score'] = df['score'].round(decimals=0)\n",
    "        \n",
    "    # interpolate NaN labels for each fips code\n",
    "    for fips in df.index.unique():\n",
    "        df.loc[fips, 'score'] = interpolate_nans(df.loc[fips]['score'].to_numpy(), \n",
    "                                                 pkind)\n",
    "    \n",
    "    if (pkind == 'nearest') and rnd: #the interpolator outputs floats\n",
    "        df = df.astype({'score': 'int32'}, copy=False)\n",
    "    return df \n",
    "\n",
    "def extract_y(df):\n",
    "    '''input df is sorted has fips index, column is label'''\n",
    "    # training y can have rounded or not rounded labels\n",
    "    # score is already in the correct type (float or int)\n",
    "    \n",
    "    for i in range(1,7):\n",
    "        col_name = 'w' + str(i)\n",
    "        empty = np.empty(len(df))\n",
    "        empty[:] = np.NaN\n",
    "        df[col_name] = empty\n",
    "    \n",
    "    for fips in df.index.unique():\n",
    "        subdf = df.loc[fips]\n",
    "        for i in range(1,7):\n",
    "            # shift the dataframe\n",
    "            col_name = 'w' + str(i)\n",
    "            df.loc[fips, col_name] = subdf[['score']].shift(periods= -7 * i)['score']\n",
    "    return df #outputs df with score w1,w2,w3, includes NaNs etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b219de7-3c77-444f-bcf6-0decb5c9831c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset creation\n",
    "How to deal with NaNs in the test/validation set?\n",
    "\n",
    "Begin with once a week predictions. When we predict (once a week), we will have the drought measurement of the prediction day, so we can interpolate between measurements all the way into the past. \n",
    "\n",
    "The true test accuracy can only be measured on predictions on measurement days. So we'll treat the validation data the same way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b18ec-00b5-4198-8d62-049dbb6e8f97",
   "metadata": {},
   "source": [
    "step 1: process X,y pair then remove NaN rows from X. Then we can just remove NaN rows from all subsequent y's and the indices will match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4676504-2e44-49dc-ab05-0c337a3a5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"validation_timeseries.csv\", \"test_timeseries.csv\", \n",
    "        \"train_timeseries.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "673637a3-b43f-4c93-b5f5-af261af13f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do everything to X and y in a single pass\n",
    "for file in files:\n",
    "    df = pd.read_csv(file).set_index('fips')\n",
    "    df = df\n",
    "    dfTrans = sort_df(df)\n",
    "    \n",
    "    #keep a copy of raw scores\n",
    "    score = dfTrans['score'].copy()\n",
    "    \n",
    "    dfTrans = (df.pipe(normalize)\n",
    "              .pipe(sin_cos_encoder)\n",
    "              .pipe(interpolate_round, pkind='linear', rnd=False)\n",
    "              .pipe(extract_y))\n",
    "    \n",
    "    dfTrans['score_copy'] = score\n",
    "    dfTrans.dropna(inplace=True, subset=['w1','w2','w3','w4','w5','w6'])\n",
    "    \n",
    "    #write out interpolated scores, can delete rows as needed with original scores\n",
    "    y_cols = ['date','score','w1','w2','w3','w4','w5','w6']\n",
    "    dfTrans[y_cols].to_csv('linear' + file) \n",
    "    \n",
    "\n",
    "    \n",
    "    #keep original scores with NaNs as 'score_copy', 'score' is interpolated scores\n",
    "    dfTrans.drop(columns=['w1','w2','w3','w4','w5','w6'], inplace=True)\n",
    "    dfTrans.to_csv(\"X-\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "191485a7-c174-4208-ae1d-ddf5bbbf9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out ys as pickles!!!!!!\n",
    "for file in files:\n",
    "    df = pd.read_csv(file).set_index('fips')\n",
    "    df = df[['date','score']].copy()\n",
    "    \n",
    "    for rd in [True, False]:\n",
    "        for kind in ['nearest', 'linear']:\n",
    "            dfTrans = (df.pipe(interpolate_round, pkind=kind, rnd=rd)\n",
    "                          .pipe(extract_y))\n",
    "            dfTrans.to_csv(kind + str(rd) + file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcfa97c0-4dd5-425d-8efd-80111b25a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"X-train_timeseries.csv\").set_index('fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cddd464d-8564-4a37-a17c-980b0a73ebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'PRECTOT', 'PS', 'QV2M', 'T2M', 'T2MDEW', 'T2MWET', 'T2M_MAX',\n",
       "       'T2M_MIN', 'T2M_RANGE', 'TS', 'WS10M', 'WS10M_MAX', 'WS10M_MIN',\n",
       "       'WS10M_RANGE', 'WS50M', 'WS50M_MAX', 'WS50M_MIN', 'WS50M_RANGE',\n",
       "       'score', 'sin', 'cos', 'score_copy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba488db1-b5e6-4253-a197-89989037e958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PRECTOT</th>\n",
       "      <th>PS</th>\n",
       "      <th>QV2M</th>\n",
       "      <th>T2M</th>\n",
       "      <th>T2MDEW</th>\n",
       "      <th>T2MWET</th>\n",
       "      <th>T2M_MAX</th>\n",
       "      <th>T2M_MIN</th>\n",
       "      <th>T2M_RANGE</th>\n",
       "      <th>...</th>\n",
       "      <th>WS10M_MIN</th>\n",
       "      <th>WS10M_RANGE</th>\n",
       "      <th>WS50M</th>\n",
       "      <th>WS50M_MAX</th>\n",
       "      <th>WS50M_MIN</th>\n",
       "      <th>WS50M_RANGE</th>\n",
       "      <th>score</th>\n",
       "      <th>sin</th>\n",
       "      <th>cos</th>\n",
       "      <th>score_copy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fips</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.94</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.52</td>\n",
       "      <td>2.28</td>\n",
       "      <td>4.05</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1.87</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.89</td>\n",
       "      <td>7.76</td>\n",
       "      <td>7.72</td>\n",
       "      <td>4.12</td>\n",
       "      <td>5.20</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.034328</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.49</td>\n",
       "      <td>3.94</td>\n",
       "      <td>5.69</td>\n",
       "      <td>9.57</td>\n",
       "      <td>9.53</td>\n",
       "      <td>4.05</td>\n",
       "      <td>7.91</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.74</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.051479</td>\n",
       "      <td>0.998674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>13.31</td>\n",
       "      <td>3.63</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-5.25</td>\n",
       "      <td>4.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068615</td>\n",
       "      <td>0.997643</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>-2.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-4.87</td>\n",
       "      <td>-8.94</td>\n",
       "      <td>-10.24</td>\n",
       "      <td>-10.19</td>\n",
       "      <td>-7.86</td>\n",
       "      <td>-10.07</td>\n",
       "      <td>2.21</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>-2.59</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>-2.48</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.085731</td>\n",
       "      <td>0.996318</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  PRECTOT    PS  QV2M   T2M  T2MDEW  T2MWET  T2M_MAX  T2M_MIN  \\\n",
       "fips                                                                            \n",
       "1001  2000-01-01    -2.42  3.85  1.83  1.94    6.56    6.52     2.28     4.05   \n",
       "1001  2000-01-02    -2.44  3.89  2.60  3.89    7.76    7.72     4.12     5.20   \n",
       "1001  2000-01-03     1.01  3.49  3.94  5.69    9.57    9.53     4.05     7.91   \n",
       "1001  2000-01-04    13.31  3.63 -1.40 -1.40   -0.86   -0.89    -0.59    -5.25   \n",
       "1001  2000-01-05    -2.64  4.49 -4.87 -8.94  -10.24  -10.19    -7.86   -10.07   \n",
       "\n",
       "      T2M_RANGE  ...  WS10M_MIN  WS10M_RANGE  WS50M  WS50M_MAX  WS50M_MIN  \\\n",
       "fips             ...                                                        \n",
       "1001      -1.77  ...      -0.44        -1.81  -0.68      -1.77       0.10   \n",
       "1001      -1.09  ...      -0.10        -1.67  -0.20      -1.68       0.59   \n",
       "1001      -3.86  ...       0.73        -0.60   2.00       1.71       2.74   \n",
       "1001       4.65  ...       0.15         0.32   1.20       1.50       0.61   \n",
       "1001       2.21  ...      -1.41        -1.29  -2.59      -2.96      -2.48   \n",
       "\n",
       "      WS50M_RANGE     score       sin       cos  score_copy  \n",
       "fips                                                         \n",
       "1001        -1.87  0.571429  0.017166  0.999853         NaN  \n",
       "1001        -2.27  0.714286  0.034328  0.999411         NaN  \n",
       "1001        -1.02  0.857143  0.051479  0.998674         NaN  \n",
       "1001         0.90  1.000000  0.068615  0.997643         1.0  \n",
       "1001        -0.49  1.142857  0.085731  0.996318         NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7072c-ad75-4510-8027-466299e38fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
