{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter searching using single prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from projectUtils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load our saved Data\n",
    "We can index to get submatrices for less previous observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def np_load(filename):\n",
    "    path = ''\n",
    "    return np.load(path + filename + '.npy', allow_pickle=True)\n",
    "\n",
    "X_train = np_load('X_train_14wvar')\n",
    "y_train = np_load('y_train_14wvar')\n",
    "X_valid = np_load('X_valid_14wvar')\n",
    "y_valid = np_load('y_valid_14wvar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert to multiclass\n",
    "y_train = round_and_intify(y_train)\n",
    "y_valid = round_and_intify(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal classification with aggregated binary classifiers\n",
    "https://stackoverflow.com/questions/57561189/multi-class-multi-label-ordinal-classification-with-sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with just a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set solver\n",
    "SOLVER = 'saga'\n",
    "ITERS = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training is impractically slow for anything but lbfgs, sag or saga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid searching for two different prediction weeks to inform later grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__C': 1.0,\n",
       " 'base_estimator__class_weight': None,\n",
       " 'base_estimator__dual': False,\n",
       " 'base_estimator__fit_intercept': True,\n",
       " 'base_estimator__intercept_scaling': 1,\n",
       " 'base_estimator__l1_ratio': None,\n",
       " 'base_estimator__max_iter': 250,\n",
       " 'base_estimator__multi_class': 'auto',\n",
       " 'base_estimator__n_jobs': None,\n",
       " 'base_estimator__penalty': 'l2',\n",
       " 'base_estimator__random_state': None,\n",
       " 'base_estimator__solver': 'saga',\n",
       " 'base_estimator__tol': 0.0001,\n",
       " 'base_estimator__verbose': 0,\n",
       " 'base_estimator__warm_start': False,\n",
       " 'base_estimator': LogisticRegression(max_iter=250, solver='saga'),\n",
       " 'loss': <function sklearn.metrics._regression.mean_absolute_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize base classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, f1_score\n",
    "\n",
    "base_clf = LogisticRegression(solver=SOLVER, max_iter=ITERS)\n",
    "ord_clf = OrdinalClassifier(base_clf, mean_absolute_error)\n",
    "\n",
    "ord_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_param(grid):\n",
    "    #utility to rename keys for chained estimator\n",
    "    prefix = 'base_estimator__'\n",
    "    return {prefix + k: grid[k] for k in grid.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.random import sample_without_replacement as sample\n",
    "\n",
    "#train and validate on a subset to save time\n",
    "train_num = int(y_train.shape[0] / 10)\n",
    "indices = sample(y_train.shape[0], train_num)\n",
    "\n",
    "X_t_s = X_train[indices, :]\n",
    "y_t_s = y_train[indices, :]\n",
    "\n",
    "#train on a subset to save time\n",
    "valid_num = int(y_valid.shape[0] / 10)\n",
    "val_indices = sample(y_valid.shape[0], valid_num)\n",
    "\n",
    "X_v_s = X_valid[val_indices, :]\n",
    "y_v_s = y_valid[val_indices, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "\n",
    "scorer = {'mae': make_scorer(mean_absolute_error),\n",
    "          'f1': make_scorer(f1_score, average='macro')}\n",
    "\n",
    "X = np.vstack((X_t_s, X_v_s))\n",
    "y = np.vstack((y_t_s, y_v_s))\n",
    "\n",
    "indexer = np.ones(X.shape[0], dtype=np.int8)\n",
    "indexer[ :X_t_s.shape[0] + 1] *= -1\n",
    "ps = PredefinedSplit(indexer)\n",
    "\n",
    "def search(params, X, y, X_v, y_v, name):\n",
    "    base_clf = LogisticRegression(solver=SOLVER, max_iter=ITERS)\n",
    "    ord_clf = OrdinalClassifier(base_clf, mean_absolute_error)\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    gridSearch = GridSearchCV(ord_clf, \n",
    "                              transform_param(params), \n",
    "                              scoring=scorer,\n",
    "                              n_jobs=-2,\n",
    "                              refit='mae',\n",
    "                              verbose=3,\n",
    "                              cv=ps) \n",
    "\n",
    "    gridSearch.fit(X, y)\n",
    "    save_model(gridSearch, name)\n",
    "\n",
    "    #print time\n",
    "    timer(tic)\n",
    "    \n",
    "    #evaluate\n",
    "    y_pred = gridSearch.score(X_v, y_v)\n",
    "    \n",
    "    return gridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### w6 preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w = y[:, 5]\n",
    "w_v_s = y_v_s[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 9 candidates, totalling 9 fits\n",
      "[CV 1/1] END base_estimator__C=0.5, base_estimator__l1_ratio=0.2, base_estimator__penalty=elasticnet; f1: (test=0.385) mae: (test=0.363) total time= 8.4min\n",
      "[CV 1/1] END base_estimator__C=1.0, base_estimator__l1_ratio=0.5, base_estimator__penalty=elasticnet; f1: (test=0.385) mae: (test=0.363) total time= 8.5min\n",
      "[CV 1/1] END base_estimator__C=1.0, base_estimator__l1_ratio=0.8, base_estimator__penalty=elasticnet; f1: (test=0.385) mae: (test=0.363) total time= 8.7min\n",
      "[CV 1/1] END base_estimator__C=0.5, base_estimator__l1_ratio=0.8, base_estimator__penalty=elasticnet; f1: (test=0.385) mae: (test=0.363) total time= 8.9min\n",
      "[CV 1/1] END base_estimator__C=0.5, base_estimator__l1_ratio=0.5, base_estimator__penalty=elasticnet; f1: (test=0.385) mae: (test=0.363) total time=11.3min\n",
      "[CV 1/1] END base_estimator__C=5.0, base_estimator__l1_ratio=0.2, base_estimator__penalty=elasticnet; f1: (test=0.385) mae: (test=0.363) total time= 8.1min\n",
      "[CV 1/1] END base_estimator__C=5.0, base_estimator__l1_ratio=0.5, base_estimator__penalty=elasticnet; f1: (test=0.385) mae: (test=0.363) total time= 7.6min\n",
      "[CV 1/1] END base_estimator__C=1.0, base_estimator__l1_ratio=0.2, base_estimator__penalty=elasticnet; f1: (test=0.385) mae: (test=0.363) total time= 8.3min\n",
      "[CV 1/1] END base_estimator__C=5.0, base_estimator__l1_ratio=0.8, base_estimator__penalty=elasticnet; f1: (test=0.385) mae: (test=0.363) total time= 7.7min\n",
      "Elapsed time: 26 minutes, 12 seconds\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.5,1.0,5.0],\n",
    "             'penalty': ['elasticnet'],\n",
    "             'l1_ratio': [0.2, 0.5, 0.8]}\n",
    "\n",
    "grid1 = search(param_grid, X, w, X_v_s, w_v_s, 'elasticw6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Elapsed time: 9 minutes, 23 seconds\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty': ['none']}\n",
    "\n",
    "grid1 = search(param_grid, X, w, X_v_s, w_v_s, 'nonew6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3631800843204176"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "e_3 = joblib.load('elasticw3.pkl')\n",
    "n_3 = joblib.load('nonew3.pkl')\n",
    "e_6 = joblib.load('elasticw6.pkl')\n",
    "n_6 = joblib.load('nonew6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = [e_3, n_3, e_6, n_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23603024827678512\n",
      "{'base_estimator__C': 0.5, 'base_estimator__l1_ratio': 0.8, 'base_estimator__penalty': 'elasticnet'}\n",
      "0.23569564344509134\n",
      "{'base_estimator__penalty': 'none'}\n",
      "0.36324700528675635\n",
      "{'base_estimator__C': 0.5, 'base_estimator__l1_ratio': 0.8, 'base_estimator__penalty': 'elasticnet'}\n",
      "0.3631800843204176\n",
      "{'base_estimator__penalty': 'none'}\n"
     ]
    }
   ],
   "source": [
    "for estimator in gs:\n",
    "    print(estimator.best_score_)\n",
    "    print(estimator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
